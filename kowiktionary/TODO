
1. Figure out how to use the index to quickly retrieve the relevant page.
2. Figure out how to parse the documents for relevant info (translations, hanja, definition, etc.) -- use python markdown to parse.
3. Look into more fancy matching (rather than exact kanji<->hanja match in the exactly matched file), 

4. Implement all relevant words from character search -- 
  -- parse documents and make a character -> word index
  -- then given a character, display all the words (and preferably the full hanja)
  -- then hopefully we can align with the kanji and hiragana to get possible translations


Other stretch goals:
- implement a method for guessing the same but representationally difference characters (i.e. hanja,kanji writing distinctions)
- connect with English-Korean and English-Japanese dictionary to get definitions in English, as well as, three-way agreement clusters (use English as an intermediary).

